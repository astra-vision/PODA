# PODA (OBJECT DETECTION ğŸ”¥): Prompt-driven Zero-shot Domain Adaptation
[Mohammad Fahes<sup>1</sup>](https://mfahes.github.io/),
[Tuan-Hung Vu<sup>1,2</sup>](https://tuanhungvu.github.io/),
[Andrei Bursuc<sup>1,2</sup>](https://abursuc.github.io/),
[Patrick PÃ©rez<sup>1,2</sup>](https://ptrckprz.github.io/),
[Raoul de Charette<sup>1</sup>](https://team.inria.fr/rits/membres/raoul-de-charette/)</br>
<sup>1</sup> Inria, Paris, France.

<sup>2</sup> valeo.ai, Paris, France.<br>

TL; DR: PÃ˜DA (or PODA) is a simple feature augmentation method for zero-shot domain adaptation guided by a single textual description of the target domain.

Project page: https://astra-vision.github.io/PODA/  
Paper: https://arxiv.org/abs/2212.03241

## Citation
```
@InProceedings{fahes2023poda,
  title={P{\O}DA: Prompt-driven Zero-shot Domain Adaptation},
  author={Fahes, Mohammad and Vu, Tuan-Hung and Bursuc, Andrei and P{\'e}rez, Patrick and de Charette, Raoul},
  booktitle={ICCV},
  year={2023}
}
```

# Getting started

## Clone repository

```bash
git clone -b detection git@github.com:astra-vision/PODA.git
cd PODA
```
    
## Preparing the environment
```bash
<PODA_root_dir>
conda create -n podadet pytorch==1.11.0 torchvision==0.12.0 pytorch-cuda=11.3 -c pytorch -c nvidia
conda activate podadet
MMCV_WITH_OPS=1 FORCE_CUDA=1 pip install mmcv-full==1.6.0 -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.11.0/index.html --no-cache-dir
FORCE_CUDA=1 pip install --no-cache-dir -e .
```

## Preparing datasets
Download and organize [Cityscapes](https://www.cityscapes-dataset.com/), [Cityscapes Foggy](https://people.ee.ethz.ch/~csakarid/SFSU_synthetic/) (attenuation coefficient of 0.02m-1) and [Diverse Weather Dataset](https://drive.google.com/drive/folders/1IIUnUrJrvFgPzU8D6KtV0CXa8k1eBV9B) in the following structure:

```bash
PODA_root_dir
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ cityscapes
â”‚Â Â  â”‚   â”œâ”€â”€ leftImg8bit
â”‚Â Â  â”‚   â”‚   â”œâ”€â”€ train
â”‚Â Â  â”‚   â”‚   â””â”€â”€ val
â”‚Â Â  â”‚   â””â”€â”€ annotations
â”‚Â Â  â”‚       â”œâ”€â”€ instancesonly_filtered_gtFine_train.json
â”‚Â Â  â”‚       â””â”€â”€ instancesonly_filtered_gtFine_val.json
â”‚Â Â  â”œâ”€â”€ cityscapes_foggy
â”‚Â Â  â”‚   â””â”€â”€ val
â”‚Â Â  â”‚       â”œâ”€â”€ frankfurt
â”‚Â Â  â”‚       â”‚Â Â  â”œâ”€â”€ frankfurt_000000_000294_leftImg8bit.png
â”‚Â Â  â”‚       â”‚Â Â  â””â”€â”€ ...
â”‚Â Â  â”‚       â”œâ”€â”€ lindau
â”‚Â Â  â”‚       â””â”€â”€ munster
â”‚Â Â  â””â”€â”€ diverse_weather
â”‚Â Â          â”œâ”€â”€ daytime_clear
â”‚Â Â          â”œâ”€â”€ Night-Sunny
â”‚Â Â          â”œâ”€â”€ night_rainy
â”‚Â Â          â”œâ”€â”€ dusk_rainy
â”‚Â Â          â””â”€â”€ daytime_foggy
â”‚Â Â  ...
```

## Downloading augmented features and pretrained checkpoints
[Download](https://github.com/astra-vision/PODA/releases/tag/v1.0.0) and place uncompressed files in the <PODA_root_dir> as follows:

```bash
PODA_root_dir
â”œâ”€â”€ ...
â”œâ”€â”€ augmented_feats
â”‚Â Â  â”œâ”€â”€ OD_aug_iccv
â”‚Â Â  â””â”€â”€ fog_f1_templates_100it
â”œâ”€â”€ checkpoints
â”‚Â Â  â”œâ”€â”€ clip_visual_encoder_resnet50.pth
â”‚Â Â  â””â”€â”€ ...
â”œâ”€â”€ ...
â””â”€â”€ work_dirs
â”‚Â Â  â”œâ”€â”€ faster_rcnn_r50_fpn_1x_pretrainedCLIP_cityscapes
â”‚Â Â  â”‚Â Â  â””â”€â”€ latest.pth
â”‚Â Â  â”‚Â Â  
â”‚Â Â  â”œâ”€â”€ faster_rcnn_r50_fpn_1x_pretrainedCLIP_cityscapes_PODA_fog
â”‚Â Â  â”œâ”€â”€ faster_rcnn_r101_fpn_1x_pretrainedCLIP_diverseweather_dayclearnew_lr4e-3
â”‚Â Â  â”œâ”€â”€ faster_rcnn_r101_fpn_1x_pretrainedCLIP_diverseweather_dayclearnew_lr4e-3_srconly_lr4e-4_finetuneCLIP
â”‚Â Â  â”œâ”€â”€ faster_rcnn_r101_fpn_1x_pretrainedCLIP_diverseweather_dayclearnew_lr4e-3_srconly_lr4e-4_finetuneCLIP_latest_PODA_dayfog_lr4e-4_finetuneCLIP
â”‚Â Â  â”œâ”€â”€ faster_rcnn_r101_fpn_1x_pretrainedCLIP_diverseweather_dayclearnew_lr4e-3_srconly_lr4e-4_finetuneCLIP_latest_PODA_duskrain_lr4e-4_finetuneCLIP
â”‚Â Â  â”œâ”€â”€ faster_rcnn_r101_fpn_1x_pretrainedCLIP_diverseweather_dayclearnew_lr4e-3_srconly_lr4e-4_finetuneCLIP_latest_PODA_night_lr4e-4_finetuneCLIP
â”‚Â Â  â””â”€â”€ faster_rcnn_r101_fpn_1x_pretrainedCLIP_diverseweather_dayclearnew_lr4e-3_srconly_lr4e-4_finetuneCLIP_latest_PODA_nightrain_lr4e-4_finetuneCLIP
â”œâ”€â”€ ...
```

## Training & Testing
### Src-domain Cityscapes + zero-shot adaptation to fog weather
```bash
# src-only
python tools/train.py ./configs/PODA/faster_rcnn_r50_fpn_1x_pretrainedCLIP_cityscapes.py --auto-scale-lr

# .. then train with PODA's augmented features of fog
python tools/train.py ./configs/PODA/faster_rcnn_r50_fpn_1x_pretrainedCLIP_cityscapes_PODA_fog.py --auto-scale-lr

# test on Cityscapes-Foggy
python tools/test.py ./configs/PODA/faster_rcnn_r50_fpn_1x_pretrainedCLIP_cityscapes_PODA_fog.py ./work_dirs/faster_rcnn_r50_fpn_1x_pretrainedCLIP_cityscapes_PODA_fog/latest.pth --eval bbox
```

### Src-domain Day-Clear + zero-shot adaptation to diverse weathers in DWD
```bash
# src-only (2 phases)
python tools/train.py ./configs/PODA/faster_rcnn_r101_fpn_1x_pretrainedCLIP_diverseweather_dayclearnew_lr4e-3.py --auto-scale-lr
python tools/train.py ./configs/PODA/faster_rcnn_r101_fpn_1x_pretrainedCLIP_diverseweather_dayclearnew_lr4e-3_srconly_lr4e-4_finetuneCLIP.py --auto-scale-lr

# .. then train with PODA's augmented features, e.g. night
python tools/train.py ./configs/PODA/faster_rcnn_r101_fpn_1x_pretrainedCLIP_diverseweather_dayclearnew_lr4e-3_srconly_lr4e-4_finetuneCLIP_latest_PODA_night_lr4e-4_finetuneCLIP.py --auto-scale-lr

# test on DWD, e.g. night
python tools/test.py ./configs/PODA/faster_rcnn_r101_fpn_1x_pretrainedCLIP_diverseweather_dayclearnew_lr4e-3_srconly_lr4e-4_finetuneCLIP_latest_PODA_night_lr4e-4_finetuneCLIP.py ./work_dirs/faster_rcnn_r101_fpn_1x_pretrainedCLIP_diverseweather_dayclearnew_lr4e-3_srconly_lr4e-4_finetuneCLIP_latest_PODA_night_lr4e-4_finetuneCLIP/latest.pth --eval mAP

```

### Results
We show some results of PÃ˜DA for object detection. The metric is mAP%.

â—â—â— [08/07/2024] For the Night-Clear and Day-Foggy results, we corrected the evaluation bug from the original paper where the test split was mistakenly used instead of the train split for testing.

<p align="center">
  <img src="./images/PODA_for_OD.png/" style="width:75%"/>
</p>


# License
PÃ˜DA is released under the [Apache 2.0 license](./LICENSE).

# Acknowledgement
The codebase heavily depends on the [mmdetection v2.28.2](https://github.com/open-mmlab/mmdetection/releases/tag/v2.28.2) and uses code from [CLIP](https://github.com/openai/CLIP)
